Architectural Overview
======================
This is a sketch of the basic idea, starting from the simplest example.

A single pipeline
-----------------
The simplest example is a pipeline connecting two endpoints.

Consider a single source (of "sensory input" coming from the external
environment) and a single sink (a "motor" that can accept data, and
affect the external world in some way.)  For this most basic
example (coded up in the [examples](examples/xterm-bridge.scm)),
two xterms are used. You can type into one (this is the "sensory input")
while the second xterm displays the text generated by an agent. For
this demo, the agent is just a single pipe, from source to sink, and
all it does is to copy the data. It's the minimal non-trivial agent:
it passes input directly to output. You type into one terminal, and
whatever you type in shows up in the other terminal. (The minimal agent
would be the null agent: ignores everything and does nothing.)

The hard part in implementing the above is mapping capabilities to
actions.

The xterm has four capabilities: describe, open, read, write. The
"describe" capability is "god-given", it always exists, and so the
"lookat" action `(cog-execute! (LookatLink ...))` will always return a
description. For the xterm, the description is:
```
   (OPEN- & TXT+) or  (WRITE- & TXT-)
```
The above uses the abstract Link Grammar (LG) notation for connectors and
disjuncts. The `OPEN-` connector says that you may send the "open" command
as a valid message to the xterm device. The `(OPEN- & TXT+)` disjunct says
that, if you send the "open" message, you will get back a text-source, a
stream that can spew endless amounts of text.

The `WRITE-` connector says that you can send the "write" message. The
`(WRITE- & TXT-)` disjunct says that if you send the "write" message,
you must also provide a text source. You must provide a readable
text-pipe from which text-data can be sucked out of, and written into
the external environment.

Clearly, `TXT-` can be hooked up to `TXT+` to form an LG link. However,
the linkage is incomplete, because `OPEN- and WRITE-` remain
unconnected.   For that, an agent is needed: the agent is able to
provide the connectors needed to obtain a full linkage, completing the
diagram. By examination, the agent needs to be `(OPEN+ & WRITE+)` Thus,
the Link Grammar dictionary is:
```
   agent: (OPEN+ & WRITE+);
   xterm: (OPEN- & TXT+) or (WRITE- & TXT-);
```
The "sentence" to parse is
```
   "xterm agent xterm"
```
and the parse is the LG diagram
```
      +-------------> TXT ------>+
      +<-- OPEN <--+--> WRITE -->+
      |            |             |
    xterm        agent         xterm
```
The above diagram describes a system consisting of one sensory device
(the xterm on the left), one motor device (the xterm on the right) and an
agent that is capable of triggering the open and write commands, so as
to make text flow, from the input device to the output device.

The above is a linkage, and it is the only possible linkage for the bag
of two xterms and this particular kind of agent.  If the Link Grammar
generator were set to run free on this bag-of-parts list, this is the
only valid diagram that can result.

Generic linkages
----------------
Using an electronics analogy, the parts list is the BOM (Bill of
Material) and it's like you have a bag with resistors, capacitors,
transistors, and you shake it around, and circuits fall out. The only
valid circuits are those which have all wires fully connected (soldered
together). The Link Grammar linkage is the same thing as the electronics
EDA netlist.

Of course, most random electronic circuits are going to be useless.  If
only there was some way of having a training corpus of electronic
circuits, and some way of using deep learning to create a LECM (Large
Electronic Circuit Model) ... but alas, no such system exists.

In biology, there is this concept of "assembly theory". There is a
concept of autopoesis or autopoetic systems, of self-assembling systems.
You throw a bunch of lipids into a bag, shake it, and out pops a bilipid
layer.  Throw a bunch of amino acids into a bag, shake it, and out pops
a protein. Throw in some ribose sugars, out pops a DNA strand. Things
connect up to other things. The connection process sometimes seems
mysterious. There are (electron) affinities on each connector. Each
connector (each chemical atom) is endowed with a collection (set,
vector) of Bayesian priors. This set of priors is called a quantum
"mixed state"; it is a weighted collection of "pure states"
(unconnected, free connectors, in the form of bra and ket). The mixed
state assigns a likelihood (a "Bayesian prior", a single number) to
each pure state in the mixture (to each possilbility) The actual hookup,
where atoms/molecules/electronic bonds actually connect, is a selection
of one of these possible connectors from the set of disjuncts, weighted
by the "cost" (It's called "cost" in link-grammar, it's called "enthalpy"
in chemistry.) The "big idea" from Bill Friston for how to build AI
can be understood as a mixed state of Bayesian priors. Hooking up is
tensor contraction, weighted as a maxied state, so a different hookup
for each "possible world" of the "many worlds". But I digress.

Chatbots and Agents
-------------------
Returning to the base example. Consider adding a chatbot to this mix.
A chabot is a processing device that can accept text as input, and
generate text as output, and so is decorated with (described by) a
disjunct that is `(TXT- & TXT+)`.

The corresponding LG dictionary is
```
   ioagent: (OPEN+ & WRITE+);
   chatbot: (TXT- & TXT+);
   xterm: (OPEN- & TXT+) or (WRITE- & TXT-);
```
and one possible linkage (circuit diagram) is:
```
      +------------> TXT --+----> TXT --->+
      +<-- OPEN <--+-------|---> WRITE -->+
      |            |       |              |
    xterm       ioagent  chatbot       xterm
```
This is perhaps the simplest example of hooking up one sensory device
(source of data from the environment) and one motor (device capable of
acting upon the environment) to some machine (the chatbot) that does
some "data processing" in the middle.

Some subtle points: in general, for some sensory device, we don't know
what kind of data it delivers or accepts. That's why `TXT+` and `TXT-`
are needed. Here, `TXT` is a type-theory type. It's a class-label stuck
onto the kinds of messages that can flow about. Likewise, `OPEN` and
`WRITE` are also types. Sensory devices will typically accept `OPEN`
messages, and motors will typically accept `WRITE`, it is not obvious
that this is always the case. This is why these messages have to be
explicitly described in the device description.

Whether or not any given device has "open" and "write" methods on it is
"described" by the dictionary, which encodes the message types that can
be sent & received. So "open" and "write" become messages.

Argument Lists
--------------
The number of "arguments" and argument types for a given message is also
specified by LG connectors. For example, "open" might need a URL as an
argument.  For an IRC (Internet Relay Chat) chatbot, you need two
arguments: the name of the IRC network and also the chat channel to
join. In this case, the disjunct for IRC would be `(OPEN- & NET- & CHAN-)`
where the `NET` type is a subtype of `TXT` and `CHAN` is also a subtype
of `TXT`, and any agent attempting to open an IRC chat needs to provide
text strings for these two. Those text strings must "come from
somewhere", they don't just magically appear.

They might, for example, come from an xterm, where a human user types
them in. This is just like a web-browser, where the URL bar is like the
xterm, it allows a human user to type in a URL, which then gets piped
along. Just to be clear, the GUI on a web browser would also have a
disjunct like `(OPEN- & FLOAT+ & FLOAT+)` which says that, after
opening, the web browser promises to generate a click-stream of x,y
window coords. There's also a CSS agent that's got a `(FLOAT- & FLOAT- & URL+)`
that says it will accept a pair of window x,y coordinates, and return
the URL that was actually clicked on by the user.

Connector Sex
-------------
The above examples use heterosexual +/- marks on the connectors, which,
in the above examples, stand for "input" and "output". Reality is more
complicated, and so the Atomese connectors have a `SexNode` which can be
`+` or `-` but can also be other things with different kinds of mating
rules.  The `+`/`-` rules are enough to implement classical lambda
calculus and beta reduction, so such a language is "Turing complete".
Although lambda calculus is great for conventional sofware
programming (e.g. the Lisp, Scheme programming languages), it is not
appropriate for network descriptions.

To belabor the point: classical Link Grammar uses `+`/`-` connector
directions in place of beta-reduction. A classical LG disjunct like
`S- & O+`, denoting a transitive verb that connects to a subject `S` and
an object `O` could have been written using typed lambdas as
```
   lambda:O.x:S
```
which is just `lambda.x` there `x` is typed to be `S` and the result of
the beta-reduction with `x` (a common noun) is of type `O`. Clearly,
using typed lambda calculus is awkward for expressing grammatical rules.

A differrent solution to this problem is seen in pregroup grammars and
in combinatory categorial grammars (CCG), which use forward and
backslashes to indicate direction. Thus, notations like `S/NP` or
`VP\S` show up in those notational systems. The slashes are type
constriuctors, and `VP\S` is the construction of a type that indicates
the object of a transitive verb. In Link Grammar, this is isomorphic
to the `O+` connector. The isomorphism is explicitly given in
[this PDF](https://github.com/opencog/atomspace/raw/master/opencog/sheaf/docs/ccg.pdf).

There are only two slash directions in CCG for the same reason that
there are only `+` and `-` in classical Link Grammar: it works just fine
for the English language. For languages that have freer word-order,
subjects, objects, verbs, adjectives can appear in any fairly loose
order. Classical Link Grammar was patched up to also provide `h` and `t`
connector types, denoting `head` and `tail` in a conventional, classical
dependency grammar formulation. And so now, instead of two
connector-direction types, there are four. Each set is heterosexual, so
`+` mates to `-` and `h` mates to `t`, but the combinations are more
complicated: `h+` can mate to `t-` but not `t+` or `h-`, and so on.

To deal with more complex mating rules than just "input" and "output"
or "command" and "result", while also avoiding the need to to
"Schonfinkelize" or "curry" the "arguments" to a lambda, Atomese
introduces the `SexNode`, so as to provide more complex mating rules.

To recap: lambdas and beta-reduction is sufficient to get a
Turing-complete system, but leads to awkward notation for
daggar-symmetric monoidal categories and linear type systems, where
two directions need to be acknowledged. For most natural langauge,
e.g. English, it is enough to throw away the "symmetric" part of
the category, and two directions are still enough. For free-word-order
langages (or freer) such as Turkish, Lithuanian, Finnish, etc. it is
convenient to have more than two connection possibilities. The `SexNode`
provides a good way to do this, in Atomese.

Similar Systems
Please note that ROS (the Robot Operating System) already implements maybe half or 2/3rds of what I describe above. The LG links are unix pipes and/or tcpip sockets. The "dictionary" is actually a YAML file that describes the motor and/or sensor. Then there are additional YAML files that provide the netlist of what hooks up to what. The problem is, of course, the YAML is not written in link-grammar format, nor is int in Atomese format, so you can't just slap around some Atomese can get a working ROS netlist out of it. And, if you have used ROS, then you know that writing ROS YAML is just about as hard as writing Atomese: they're both annoyingly difficult to tweak.

If you use github actions, some of the above might remind you of the github actions or circleci  YML files. This is not an accident: the circleci files are describing a process network flow to perform unit tests, where the sensory device is a read of a git repo, the agents and actions are compile & run of the unit tests, and the output is whether the unit tests passed or failed.

If you've ever screwed around with javascript node.js then you know ` package.json` and `package-lock.json` These are sensory-device description files (or more accurately, agent-description files), in that they describe what this particular node.js device provides: the inputs, the outputs. You then use `npm run make` to parse the system and perform all the hookups. You will also be familiar with the carpet burns you get from screwing the electron. hooking together open connectors into a function network is difficult.

There's no "one ring to rule them all". I am not aware of any generic comp-sci theory for exploring the autogeneration of networks.  Doing Atomese Sensory is sort of my personal best-guess for the generic theory/system of "making things hook together into a sensible autopoetic system". The "basal cognition" for agent-environment interaction.

Anyway, this is the current status of the language-learning effort. The demos work but are incomplete. Version 0.2 at https://github.com/opencog/sensory


